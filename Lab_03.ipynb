{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment 3: Word2Vec Training on Medical Corpus with Bigram Detection"
      ],
      "metadata": {
        "id": "hCI1Cpg4-kKX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElaGrmoU-XMA",
        "outputId": "5f6ddfb4-b3c0-46fe-f77a-a0dcdebc1e96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scipy, gensim\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.14.1\n",
            "    Uninstalling scipy-1.14.1:\n",
            "      Successfully uninstalled scipy-1.14.1\n",
            "Successfully installed gensim-4.3.3 scipy-1.13.1\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "hBIOgAmG_P8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "from gensim.models.phrases import Phrases, Phraser\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA"
      ],
      "metadata": {
        "id": "xQovcgZp_Pez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read medical corpus from an external file"
      ],
      "metadata": {
        "id": "C0DP9meT_T79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/Colab Notebooks/medical_corpus.txt\", \"r\") as file:\n",
        "    corpus = [line.strip() for line in file if line.strip()]"
      ],
      "metadata": {
        "id": "2aKUk3Mq_Ue0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Refined stopword list"
      ],
      "metadata": {
        "id": "uFQ2d18O_ZuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = {\"the\", \"a\", \"is\", \"for\", \"with\", \"to\", \"of\", \"and\", \"in\", \"can\", \"are\"}\n",
        "# Tokenization with stopword removal\n",
        "tokenized_sentences = [\n",
        "    [word for word in sentence.lower().split() if word not in stopwords]\n",
        "    for sentence in corpus\n",
        "]"
      ],
      "metadata": {
        "id": "6W9IYld6_acG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Detect bigrams to capture word combinations (e.g., \"blood sugar\", \"high pressure\")"
      ],
      "metadata": {
        "id": "kdgRznf7_dw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bigram = Phrases(tokenized_sentences, min_count=2, threshold=5)\n",
        "bigram_phraser = Phraser(bigram)\n",
        "tokenized_sentences = [bigram_phraser[sentence] for sentence in tokenized_sentences]"
      ],
      "metadata": {
        "id": "RuFt3j5L_egN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Word2Vec model with improved parameters"
      ],
      "metadata": {
        "id": "x4BJmLy0_hYE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Word2Vec(tokenized_sentences, vector_size=150, window=5, min_count=2, epochs=300, sg=1, hs=1,\n",
        "negative=0)"
      ],
      "metadata": {
        "id": "xk9m07Q0_h6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Display similar words"
      ],
      "metadata": {
        "id": "vGFOJjIF_k7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "diabetes_similar = [(word, round(sim, 2)) for word, sim in model.wv.most_similar(\"diabetes\", topn=5)]\n",
        "print(\"Words similar to 'diabetes':\", diabetes_similar)\n",
        "hypertension_similar = [(word, round(sim, 2)) for word, sim in model.wv.most_similar(\"hypertension\",\n",
        "topn=5)]\n",
        "print(\"Words similar to 'hypertension':\", hypertension_similar)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fP2HPz_M_l1Z",
        "outputId": "317c7938-b8a8-4e13-d87e-243e474153ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words similar to 'diabetes': [('lifestyle', 0.12), ('disease.', 0.11), ('diet', 0.08), ('sugar', 0.07), ('diabetes.', 0.06)]\n",
            "Words similar to 'hypertension': [('disease.', 0.09), ('risk', 0.05), ('high', 0.03), ('diet', 0.01), ('blood', 0.01)]\n"
          ]
        }
      ]
    }
  ]
}